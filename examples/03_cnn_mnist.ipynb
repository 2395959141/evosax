{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Evolving a MNIST CNN with OpenES\n",
    "### [Last Update: February 2022][![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/evosax/blob/main/examples/03_cnn_mnist.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "!pip install git+https://github.com/RobertTLange/evosax.git@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParameterReshaper: More than one device detected. Please make sure that the ES population size divides evenly across the number of devices to pmap/parallelize over.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from evosax import OpenES, ParameterReshaper, NetworkMapper\n",
    "from evosax.problems import VisionFitness\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "network = NetworkMapper[\"CNN\"](\n",
    "        depth_1=1,\n",
    "        depth_2=1,\n",
    "        features_1=8,\n",
    "        features_2=16,\n",
    "        kernel_1=5,\n",
    "        kernel_2=5,\n",
    "        strides_1=1,\n",
    "        strides_2=1,\n",
    "        num_linear_layers=0,\n",
    "        num_output_units=10,\n",
    "    )\n",
    "pholder = jnp.zeros((1, 28, 28, 1))\n",
    "params = network.init(\n",
    "    rng,\n",
    "    x=pholder,\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "param_reshaper = ParameterReshaper(params['params'])\n",
    "test_param_reshaper = ParameterReshaper(params['params'], n_devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cognition/home/RobTLange/anaconda/envs/snippets/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SupervisedFitness: More than one device detected. Please make sure that the ES population size divides evenly across the number of devices to pmap/parallelize over.\n"
     ]
    }
   ],
   "source": [
    "# Set up the dataloader for batch evaluations (may take a sec)\n",
    "train_evaluator = VisionFitness(\"MNIST\", batch_size=1024, test=False)\n",
    "test_evaluator = VisionFitness(\"MNIST\", batch_size=10000, test=True, n_devices=1)\n",
    "\n",
    "train_evaluator.set_apply_fn(param_reshaper.vmap_dict, network.apply)\n",
    "test_evaluator.set_apply_fn(param_reshaper.vmap_dict, network.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax import OpenES\n",
    "strategy = OpenES(popsize=100, num_dims=param_reshaper.total_params, opt_name=\"adam\")\n",
    "es_params = {\n",
    "    \"sigma_init\": 0.01,  # Initial scale of isotropic Gaussian noise\n",
    "    \"sigma_decay\": 0.999,  # Multiplicative decay factor\n",
    "    \"sigma_limit\": 0.01,  # Smallest possible scale\n",
    "    \"lrate_init\": 0.001,  # Initial learning rate\n",
    "    \"lrate_decay\": 0.9999,  # Multiplicative decay factor\n",
    "    \"lrate_limit\": 0.0001,  # Smallest possible lrate\n",
    "    \"beta_1\": 0.99,   # Adam - beta_1\n",
    "    \"beta_2\": 0.999,  # Adam - beta_2\n",
    "    \"eps\": 1e-8,  # eps constant,\n",
    "    \"init_min\": 0.0,  # Range of parameter archive initialization - Min\n",
    "    \"init_max\": 0.0,  # Range of parameter archive initialization - Max\n",
    "    \"clip_min\": -10,  # Range of parameter proposals - Min\n",
    "    \"clip_max\": 10  # Range of parameter proposals - Max\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax import FitnessShaper\n",
    "fit_shaper = FitnessShaper(centered_rank=True,\n",
    "                           z_score=True,\n",
    "                           w_decay=0.1,\n",
    "                           maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cognition/home/RobTLange/anaconda/envs/snippets/lib/python3.8/site-packages/jax/_src/dispatch.py:232: UserWarning: The jitted function reshape_network includes a pmap. Using jit-of-pmap can lead to inefficient data movement, as the outer jit does not preserve sharded data representations and instead collects input and output arrays onto a single device. Consider removing the outer jit unless you know what you're doing. See https://github.com/google/jax/issues/2926.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 0 | Train Acc: 0.10170897841453552 | Test Acc: 0.10279999673366547\n",
      "Generation: 100 | Train Acc: 0.13413085043430328 | Test Acc: 0.11589999496936798\n",
      "Generation: 200 | Train Acc: 0.27433592081069946 | Test Acc: 0.274399995803833\n",
      "Generation: 300 | Train Acc: 0.6929785013198853 | Test Acc: 0.7301999926567078\n",
      "Generation: 400 | Train Acc: 0.7566698789596558 | Test Acc: 0.7777999639511108\n",
      "Generation: 500 | Train Acc: 0.7677441239356995 | Test Acc: 0.8165000081062317\n",
      "Generation: 600 | Train Acc: 0.8138769268989563 | Test Acc: 0.8417999744415283\n",
      "Generation: 700 | Train Acc: 0.82777339220047 | Test Acc: 0.852899968624115\n",
      "Generation: 800 | Train Acc: 0.8446386456489563 | Test Acc: 0.8614999651908875\n",
      "Generation: 900 | Train Acc: 0.8374804258346558 | Test Acc: 0.8689000010490417\n",
      "Generation: 1000 | Train Acc: 0.8595898151397705 | Test Acc: 0.8758999705314636\n",
      "Generation: 1100 | Train Acc: 0.8499706983566284 | Test Acc: 0.8810999989509583\n",
      "Generation: 1200 | Train Acc: 0.8672558665275574 | Test Acc: 0.885699987411499\n",
      "Generation: 1300 | Train Acc: 0.869677722454071 | Test Acc: 0.8908999562263489\n",
      "Generation: 1400 | Train Acc: 0.8767675757408142 | Test Acc: 0.8962000012397766\n",
      "Generation: 1500 | Train Acc: 0.8863476514816284 | Test Acc: 0.8981999754905701\n",
      "Generation: 1600 | Train Acc: 0.8994433283805847 | Test Acc: 0.9016000032424927\n",
      "Generation: 1700 | Train Acc: 0.8740527033805847 | Test Acc: 0.9049999713897705\n",
      "Generation: 1800 | Train Acc: 0.8863281011581421 | Test Acc: 0.90829998254776\n",
      "Generation: 1900 | Train Acc: 0.894335925579071 | Test Acc: 0.9104999899864197\n",
      "Generation: 2000 | Train Acc: 0.8915820121765137 | Test Acc: 0.91239994764328\n",
      "Generation: 2100 | Train Acc: 0.9054296612739563 | Test Acc: 0.9147999882698059\n",
      "Generation: 2200 | Train Acc: 0.8979394435882568 | Test Acc: 0.9159999489784241\n",
      "Generation: 2300 | Train Acc: 0.8965722322463989 | Test Acc: 0.9194999933242798\n",
      "Generation: 2400 | Train Acc: 0.9103417992591858 | Test Acc: 0.9205999970436096\n"
     ]
    }
   ],
   "source": [
    "num_generations = 2500\n",
    "print_every_k_gens = 100\n",
    "state = strategy.initialize(rng, es_params)\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    rng, rng_ask, rng_eval = jax.random.split(rng, 3)\n",
    "    x, state = strategy.ask(rng_ask, state, es_params)\n",
    "    reshaped_params = param_reshaper.reshape(x)\n",
    "    # rollout will pytree w. train_acc, train_loss\n",
    "    train_loss, train_acc = train_evaluator.rollout(rng_eval, reshaped_params)\n",
    "    fit_re = fit_shaper.apply(x, train_loss.mean(axis=1))\n",
    "    state = strategy.tell(x, fit_re, state, es_params)\n",
    "\n",
    "    if gen % print_every_k_gens == 0:\n",
    "        # Perform evaluation for best and mean members\n",
    "        mean_params = state[\"mean\"].reshape(1, -1)\n",
    "        reshaped_test_params = test_param_reshaper.reshape(mean_params)\n",
    "        test_loss, test_acc = test_evaluator.rollout(\n",
    "            rng_eval, reshaped_test_params\n",
    "        )\n",
    "        print(f\"Generation: {gen} | Train Acc: {train_acc.mean()} | Test Acc: {test_acc.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snippets",
   "language": "python",
   "name": "snippets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
