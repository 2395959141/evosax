{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import vmap, jit\n",
    "import haiku as hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import gymnax\n",
    "from evosax.strategies.cma_es import init_strategy, ask, tell, check_termination\n",
    "from evosax.utils import (init_logger, update_logger, flat_to_network,\n",
    "                          get_total_params, get_network_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Bernoulli Bandit Env from Gymnax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, reset, step, env_params = gymnax.make(\"Bandit-misc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haiku Meta-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_episode_rollout(env_params):\n",
    "    \"\"\" Rollout a bandit episode with RNN policy. \"\"\"\n",
    "    core = hk.LSTM(32)\n",
    "    dense = hk.Linear(2)\n",
    "    lstm_state = core.initial_state(1)\n",
    "    rng = hk.next_rng_key()\n",
    "    rng, rng_reset = jax.random.split(rng)\n",
    "    \n",
    "    # Reset bandit env + placeholder network fct. (use candidate params)\n",
    "    obs, state = reset(rng_reset, env_params)\n",
    "    \n",
    "    cum_reward = 0\n",
    "    # Loop over episode timesteps and LSTM policy steps\n",
    "    # TODO: Figure out how to lax.scan with Haiku RNN forward\n",
    "    for t in range(env_params[\"max_steps\"]):\n",
    "        # Generate rng keys for action sampling and step transition\n",
    "        rng, rng_action, rng_step = jax.random.split(rng, 3)\n",
    "        # Perform forward through RNN and sample action\n",
    "        x, lstm_state = core(jnp.expand_dims(obs, 0), lstm_state)\n",
    "        logits = dense(x)\n",
    "        action = hk.multinomial(rng_action, logits, 1).squeeze()\n",
    "        # Perform step transition\n",
    "        obs, state, reward, done, _ = step(rng_step, env_params,\n",
    "                                           state, action)\n",
    "        cum_reward += reward\n",
    "    return cum_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, rng_net = jax.random.split(rng)\n",
    "rollout_episode = hk.transform(lstm_episode_rollout)\n",
    "net_params = rollout_episode.init(rng_net, env_params)\n",
    "#rollout_episode_jit = jit(rollout_episode.apply, static_argnums=2)\n",
    "#rollout_episode_jit(net_params, rng, env_params)\n",
    "rollout_episode.apply(net_params, rng, env_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandit-LSTM CMA-ES optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_no_params = get_total_params(net_params)\n",
    "network_shapes = get_network_shapes(net_params)\n",
    "print(total_no_params, network_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_rollout = jit(vmap(rollout_episode.apply, in_axes=(None, 0, None), out_axes=0), static_argnums=(2,))\n",
    "batch_keys = jax.random.split(rng, 2)\n",
    "#ep_rewards = batch_rollout(net_params, batch_keys, env_params)\n",
    "#ep_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_eval(rng, x, network_shapes, env_params):\n",
    "    \"\"\" Perform both parameter reshaping and evaluation in one go. \"\"\"\n",
    "    net_params = flat_to_network(x, network_shapes)\n",
    "    returns = batch_rollout(net_params, rng, env_params)\n",
    "    return - returns.mean()\n",
    "\n",
    "#x = jnp.zeros(total_no_params)\n",
    "#reshape_and_eval(batch_keys, x, network_shapes, env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_fitness = vmap(reshape_and_eval, in_axes=(None, 0, None, None))\n",
    "#xs = jnp.stack([x, x])\n",
    "#generation_fitness(batch_keys, xs, network_shapes, env_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 50\n",
    "pop_size = 10\n",
    "elite_size = 5\n",
    "mean_init = jnp.zeros((total_no_params, ))\n",
    "sigma_init = 1\n",
    "\n",
    "top_k = 5\n",
    "evo_logger = init_logger(top_k, total_no_params)\n",
    "params, memory = init_strategy(mean_init, sigma_init,\n",
    "                               pop_size, elite_size)\n",
    "fit = []\n",
    "for g in range(num_generations):\n",
    "    # Explicitly handle random number generation\n",
    "    rng, rng_ask, rng_eval = jax.random.split(rng, 3)\n",
    "    batch_keys = jax.random.split(rng_eval, 10)\n",
    "    # Ask for the next generation population to test\n",
    "    x, memory = ask(rng_ask, params, memory)\n",
    "    # Evaluate the fitness of the generation members\n",
    "    fitness = generation_fitness(batch_keys, x,\n",
    "                                 network_shapes, env_params)\n",
    "    \n",
    "    # x, fitness = rank_shaped_fitness(x, fitness)\n",
    "    # Tell/Update the CMA-ES with newest data points\n",
    "    memory = tell(x, fitness, params, memory)\n",
    "    evo_logger = update_logger(evo_logger, x, fitness, memory, top_k,\n",
    "                               verbose=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Evo Run Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax.visualize.plot_log import plot_fitness, plot_sigma\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "plot_fitness(evo_logger, title=\"Meta-Bandit LSTM - Performance\", ylims=(-100, -20), fig=fig, ax=axs[0])\n",
    "plot_sigma(evo_logger, title=\"Meta-Bandit LSTM - Stepsize\", ylims=(0.5, 1.2), fig=fig, ax=axs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ma-vision)",
   "language": "python",
   "name": "ma-vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
