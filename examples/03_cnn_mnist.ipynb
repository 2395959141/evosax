{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Evolving a MNIST CNN with OpenES\n",
    "### [Last Update: February 2022][![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/evosax/blob/main/examples/03_cnn_mnist.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax import Open_ES, ParameterReshaper, NetworkMapper\n",
    "from evosax.problems import SupervisedFitness\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "network = NetworkMapper[\"CNN\"](\n",
    "        depth_1=1,\n",
    "        depth_2=1,\n",
    "        features_1=8,\n",
    "        features_2=16,\n",
    "        kernel_1=5,\n",
    "        kernel_2=5,\n",
    "        strides_1=1,\n",
    "        strides_2=1,\n",
    "        num_linear_layers=0,\n",
    "        num_output_units=10,\n",
    "    )\n",
    "pholder = jnp.zeros((1, 28, 28, 1))\n",
    "params = network.init(\n",
    "    rng,\n",
    "    x=pholder,\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "param_reshaper = ParameterReshaper(params['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cognition/home/RobTLange/anaconda/envs/snippets/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Set up the dataloader for batch evaluations (may take a sec)\n",
    "evaluator = SupervisedFitness(\"MNIST\", batch_size=256)\n",
    "evaluator.set_apply_fn(network.apply)\n",
    "rollout = jax.jit(jax.vmap(evaluator.rollout, in_axes=(None, param_reshaper.vmap_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax import Open_ES\n",
    "strategy = Open_ES(popsize=100, num_dims=param_reshaper.total_params, opt_name=\"adam\")\n",
    "es_params = {\n",
    "    \"sigma_init\": 0.01,  # Initial scale of isotropic Gaussian noise\n",
    "    \"sigma_decay\": 0.999,  # Multiplicative decay factor\n",
    "    \"sigma_limit\": 0.01,  # Smallest possible scale\n",
    "    \"lrate_init\": 0.001,  # Initial learning rate\n",
    "    \"lrate_decay\": 0.9999,  # Multiplicative decay factor\n",
    "    \"lrate_limit\": 0.0001,  # Smallest possible lrate\n",
    "    \"beta_1\": 0.99,   # Adam - beta_1\n",
    "    \"beta_2\": 0.999,  # Adam - beta_2\n",
    "    \"eps\": 1e-8,  # eps constant,\n",
    "    \"init_min\": 0.0,  # Range of parameter archive initialization - Min\n",
    "    \"init_max\": 0.0,  # Range of parameter archive initialization - Max\n",
    "    \"clip_min\": -10,  # Range of parameter proposals - Min\n",
    "    \"clip_max\": 10  # Range of parameter proposals - Max\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax import FitnessShaper\n",
    "fit_shaper = FitnessShaper(centered_rank=True,\n",
    "                           z_score=True,\n",
    "                           w_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.105 0.09765625 2.3026407 2.3026216\n",
      "100 0.10601562 0.20328124 2.2948122 2.2905602\n",
      "200 0.3980078 0.42074218 2.116134 2.100343\n",
      "300 0.67105466 0.71335936 1.4127865 1.3928121\n",
      "400 0.7093359 0.76124996 0.93174905 0.83537227\n",
      "500 0.7780078 0.79531246 0.6982758 0.6634201\n",
      "600 0.8074609 0.80781245 0.61464864 0.69131184\n",
      "700 0.8813281 0.83 0.56244344 0.55927765\n",
      "800 0.8567578 0.84925777 0.4986973 0.4897943\n",
      "900 0.8617578 0.84734374 0.51981276 0.538323\n",
      "1000 0.85679686 0.88078123 0.50712556 0.40201977\n",
      "1100 0.84910154 0.86902344 0.5138326 0.47206232\n",
      "1200 0.876914 0.8602734 0.4440429 0.43906233\n",
      "1300 0.84410155 0.86960936 0.5221144 0.5351238\n",
      "1400 0.8720312 0.90199214 0.482296 0.3756349\n",
      "1500 0.8815625 0.87324214 0.4720793 0.45056823\n",
      "1600 0.9103515 0.8879687 0.38361242 0.37585488\n",
      "1700 0.92222655 0.8800781 0.36601463 0.4366532\n",
      "1800 0.8698437 0.91054684 0.38637078 0.38063183\n",
      "1900 0.90558594 0.89335936 0.3719517 0.31824312\n",
      "2000 0.8975781 0.90160155 0.3575186 0.37494323\n",
      "2100 0.90847653 0.87742186 0.33438185 0.40607253\n",
      "2200 0.89234376 0.91589844 0.3229697 0.27996787\n",
      "2300 0.89214844 0.92371094 0.30656093 0.2652912\n",
      "2400 0.90523434 0.92222655 0.33348104 0.26094848\n",
      "2500 0.90999997 0.9367187 0.30826104 0.21816196\n",
      "2600 0.91999996 0.9238281 0.24380745 0.22480671\n",
      "2700 0.9039062 0.9386328 0.30765826 0.23362468\n",
      "2800 0.9289062 0.924375 0.24001071 0.23566718\n",
      "2900 0.92796874 0.9302344 0.2749399 0.21600597\n",
      "3000 0.92636716 0.9325 0.22460774 0.2787947\n",
      "3100 0.9421875 0.9269531 0.21090163 0.25887957\n",
      "3200 0.936289 0.9336328 0.24157473 0.23785968\n",
      "3300 0.9395703 0.9199609 0.2000696 0.26451\n",
      "3400 0.94402343 0.94124997 0.21996848 0.19241585\n",
      "3500 0.9351562 0.95097655 0.19481708 0.17602955\n",
      "3600 0.94554687 0.93402344 0.24742313 0.20048533\n",
      "3700 0.95453125 0.944414 0.19820862 0.2032854\n",
      "3800 0.94433594 0.9501172 0.18278109 0.13721146\n",
      "3900 0.93152344 0.95667964 0.17876032 0.13768291\n",
      "4000 0.94757813 0.9525 0.17148498 0.16343552\n",
      "4100 0.9420703 0.9560156 0.16924927 0.12404415\n",
      "4200 0.93902344 0.9580859 0.18133315 0.15634735\n",
      "4300 0.95124996 0.9422656 0.16281407 0.18533775\n",
      "4400 0.944375 0.96984375 0.13703583 0.11634418\n",
      "4500 0.9455859 0.92710936 0.18012428 0.26359662\n",
      "4600 0.94816405 0.95210934 0.16598609 0.1436694\n",
      "4700 0.9595703 0.96449214 0.14181228 0.11954234\n",
      "4800 0.94785154 0.96937495 0.15891358 0.14648165\n",
      "4900 0.9438281 0.9542968 0.1551541 0.15062417\n",
      "5000 0.9478125 0.97042966 0.17294884 0.08979176\n",
      "5100 0.9601562 0.9809765 0.14208718 0.095989615\n",
      "5200 0.9747656 0.9502734 0.15269706 0.14239033\n",
      "5300 0.9684375 0.9571875 0.11014618 0.13726364\n",
      "5400 0.9592969 0.9657812 0.12329985 0.10117158\n",
      "5500 0.97679687 0.98375 0.12028188 0.0582873\n",
      "5600 0.9685547 0.95996094 0.118165754 0.12155016\n",
      "5700 0.94535154 0.9771094 0.13650411 0.08170278\n",
      "5800 0.9607422 0.9552734 0.108447015 0.13821468\n",
      "5900 0.9746484 0.96511716 0.12213312 0.15204622\n",
      "6000 0.9660156 0.9732031 0.12898128 0.08934663\n",
      "6100 0.9597656 0.97542965 0.14988479 0.08057783\n",
      "6200 0.96949214 0.94378906 0.1134395 0.17329437\n",
      "6300 0.9659375 0.95210934 0.13203396 0.16291782\n",
      "6400 0.9496875 0.95386714 0.11556578 0.12780784\n",
      "6500 0.9582422 0.96542966 0.12983726 0.111103624\n",
      "6600 0.9788672 0.95585936 0.1008802 0.14619046\n",
      "6700 0.9573828 0.97605467 0.11249445 0.08261572\n",
      "6800 0.97437495 0.975664 0.105542935 0.10329602\n",
      "6900 0.9672656 0.9643359 0.082209446 0.10035786\n",
      "7000 0.96449214 0.96687496 0.12451016 0.11123225\n",
      "7100 0.9744531 0.9738672 0.100505635 0.07478674\n",
      "7200 0.96128905 0.9847656 0.115913615 0.050064743\n",
      "7300 0.9712109 0.9768359 0.112618715 0.081703015\n",
      "7400 0.9593359 0.9438281 0.115980215 0.15102865\n"
     ]
    }
   ],
   "source": [
    "num_generations = 7500\n",
    "print_every_k_gens = 100\n",
    "state = strategy.initialize(rng, es_params)\n",
    "\n",
    "for gen in range(num_generations):\n",
    "    rng, rng_init, rng_ask, rng_eval = jax.random.split(rng, 4)\n",
    "    x, state = strategy.ask(rng_ask, state, es_params)\n",
    "    reshaped_params = param_reshaper.reshape(x)\n",
    "    # rollout will pytree w. test_acc, test_loss, train_acc, train_loss\n",
    "    fitness_loss = []\n",
    "    # run 4 sequential batch evals (circumvent accelerator memory problems)\n",
    "    for i in range(4):\n",
    "        rng_eval, rng_eval_i = jax.random.split(rng_eval)\n",
    "        fitness = rollout(rng_eval_i, reshaped_params)\n",
    "        fitness_loss.append(fitness['train_loss'])\n",
    "    \n",
    "    fitness_loss = jnp.mean(jnp.stack(fitness_loss, axis=1), axis=1)\n",
    "    fit_re = fit_shaper.apply(x, fitness_loss)\n",
    "    state = strategy.tell(x, fit_re, state, es_params)\n",
    "    if gen % print_every_k_gens == 0:\n",
    "        print(gen, fitness['train_acc'].mean(), fitness['test_acc'].mean(), \n",
    "              fitness_loss.mean(), fitness['test_loss'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snippets",
   "language": "python",
   "name": "snippets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
