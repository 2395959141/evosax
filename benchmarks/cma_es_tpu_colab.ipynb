{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python3 (ma-vision)",
      "language": "python",
      "name": "ma-vision"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "cma_es_tpu_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzmEJ9GnySub",
        "outputId": "391008fa-b33f-4d19-8ab3-e0eea4a78ef7"
      },
      "source": [
        "!ls\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!git clone https://username:password@github.com/RobertTLange/evosax.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jWGFRRayZn-",
        "outputId": "0da85f30-1551-4f1a-baf6-a37de58effa0"
      },
      "source": [
        "%cd gdrive/My Drive/evosax\n",
        "! pip install -e ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/evo_benchmark/evosax\n",
            "Obtaining file:///content/gdrive/My%20Drive/evo_benchmark/evosax\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.6/dist-packages (from evosax==0.0.1) (0.2.4)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.6/dist-packages (from evosax==0.0.1) (0.1.57+cuda101)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from evosax==0.0.1) (0.17.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax->evosax==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jax->evosax==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from jax->evosax==0.0.1) (1.19.4)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.6/dist-packages (from jaxlib->evosax==0.0.1) (1.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jaxlib->evosax==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->evosax==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->evosax==0.0.1) (1.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->jax->evosax==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->evosax==0.0.1) (0.16.0)\n",
            "Installing collected packages: evosax\n",
            "  Found existing installation: evosax 0.0.1\n",
            "    Can't uninstall 'evosax'. No files were found to uninstall.\n",
            "  Running setup.py develop for evosax\n",
            "Successfully installed evosax\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1rICwF3yT45",
        "outputId": "1daf1c7c-0696-4ff7-ef98-4bf9c4b70e9a"
      },
      "source": [
        "!pip install jax==0.2.4\n",
        "!pip install jaxlib==0.1.57\n",
        "!pip install commentjson"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jax==0.2.4 in /usr/local/lib/python3.6/dist-packages (0.2.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jax==0.2.4) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from jax==0.2.4) (1.19.4)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax==0.2.4) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->jax==0.2.4) (1.15.0)\n",
            "Requirement already satisfied: jaxlib==0.1.57 in /usr/local/lib/python3.6/dist-packages (0.1.57+cuda101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jaxlib==0.1.57) (1.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jaxlib==0.1.57) (0.10.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.6/dist-packages (from jaxlib==0.1.57) (1.12)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.6/dist-packages (from jaxlib==0.1.57) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->jaxlib==0.1.57) (1.15.0)\n",
            "Requirement already satisfied: commentjson in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: lark-parser<0.8.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from commentjson) (0.7.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GYbinHmySuj"
      },
      "source": [
        "import requests\n",
        "import os\n",
        "import numpy as np\n",
        "from jax.config import config"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1poCI-zUySuj"
      },
      "source": [
        "# TPU JAX Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6cORbWKySuk"
      },
      "source": [
        "TPU_DRIVER_MODE = 0\n",
        "\n",
        "def setup_tpu():\n",
        "    \"\"\"Sets up Colab to run on TPU.\n",
        "    Note: make sure the Colab Runtime is set to Accelerator: TPU.\n",
        "    \"\"\"\n",
        "    global TPU_DRIVER_MODE\n",
        "\n",
        "    if not TPU_DRIVER_MODE:\n",
        "        colab_tpu_addr = os.environ['COLAB_TPU_ADDR'].split(':')[0]\n",
        "        url = f'http://{colab_tpu_addr}:8475/requestversion/tpu_driver_nightly'\n",
        "        requests.post(url)\n",
        "        TPU_DRIVER_MODE = 1\n",
        "\n",
        "    # The following is required to use TPU Driver as JAX's backend.\n",
        "    config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "    config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "setup_tpu()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl109pmwySuk",
        "outputId": "f3c7188a-1863-40dc-96dd-55eea1835b35"
      },
      "source": [
        "import jax\n",
        "jax.devices()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, host_id=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, host_id=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, host_id=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, host_id=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, host_id=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, host_id=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, host_id=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, host_id=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrP3qj4KySum"
      },
      "source": [
        "# Import benchmark function from script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nva342O1g9h"
      },
      "source": [
        "from evosax.strategies.cma_es import init_strategy, ask, tell\n",
        "from evosax.utils import flat_to_mlp"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vuEjmb20UrG"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/evo_benchmark/evosax/examples')\n",
        "from ffw_pendulum import generation_rollout"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OziVI-Zn3obO"
      },
      "source": [
        "import commentjson\n",
        "def load_config(config_fname: str):\n",
        "    \"\"\" Load in a config JSON file and return as a dictionary \"\"\"\n",
        "    json_config = commentjson.loads(open(config_fname, 'r').read())\n",
        "    dict_config = DotDic(json_config)\n",
        "\n",
        "    # Make inner dictionaries indexable like a class\n",
        "    for key, value in dict_config.items():\n",
        "        if isinstance(value, dict):\n",
        "            dict_config[key] = DotDic(value)\n",
        "    return dict_config\n",
        "\n",
        "\n",
        "class DotDic(dict):\n",
        "    \"\"\"\n",
        "    a dictionary that supports dot notation\n",
        "    as well as dictionary access notation\n",
        "    usage: d = DotDict() or d = DotDict({'val1':'first'})\n",
        "    set attributes: d.val2 = 'second' or d['val2'] = 'second'\n",
        "    get attributes: d.val2 or d['val2']\n",
        "    \"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "    def __deepcopy__(self, memo=None):\n",
        "        return DotDic(copy.deepcopy(dict(self), memo=memo))\n",
        "\n",
        "    def __init__(self, dct):\n",
        "        for key, value in dct.items():\n",
        "            if hasattr(value, 'keys'):\n",
        "                value = DotDic(value)\n",
        "            self[key] = value\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptbTu2AxySum"
      },
      "source": [
        "def benchmark_accelerator(num_evaluations, population_size, hidden_size,\n",
        "                           net_config, train_config, log_config, use_jit=True,\n",
        "                           use_tpu=False):\n",
        "    \"\"\" Evaluate speed for different population sizes run. \"\"\"\n",
        "    # Want to eval gains from acc over different population size + archs\n",
        "    train_config.pop_size = population_size\n",
        "    train_config.hidden_size = hidden_size\n",
        "\n",
        "    # Start by setting the random seeds for reproducibility\n",
        "    rng = jax.random.PRNGKey(train_config.seed_id)\n",
        "\n",
        "    # Define logger, CMA-ES strategy\n",
        "    net_config.network_size[1] = int(train_config.hidden_size)\n",
        "    num_params = (net_config.network_size[0] * net_config.network_size[1]\n",
        "                  + net_config.network_size[1]\n",
        "                  + net_config.network_size[1]*net_config.network_size[2]\n",
        "                  + net_config.network_size[2])\n",
        "    mean_init = jnp.zeros(num_params)\n",
        "    elite_size = int(train_config.pop_size * train_config.elite_percentage)\n",
        "\n",
        "    generation_times = []\n",
        "    for eval in range(num_evaluations):\n",
        "        es_params, es_memory = init_strategy(mean_init,\n",
        "                                           train_config.sigma_init,\n",
        "                                           train_config.pop_size,\n",
        "                                           elite_size)\n",
        "        # Only track time for actual generation ask-tell inference\n",
        "        start_t = time.time()\n",
        "\n",
        "        # Train the network using the training loop\n",
        "        run_single_generation(rng, elite_size,\n",
        "                              train_config.num_evals_per_gen,\n",
        "                              train_config.num_env_steps,\n",
        "                              net_config.network_size,\n",
        "                              dict(train_config.env_params),\n",
        "                              es_params, es_memory, use_jit, use_tpu)\n",
        "\n",
        "        # Save wall-clock time for evaluation\n",
        "        if eval > 0:\n",
        "            generation_times.append(time.time() - start_t)\n",
        "        else:\n",
        "            jit_time = time.time() - start_t\n",
        "    return np.mean(generation_times), np.std(generation_times), jit_time\n",
        "\n",
        "\n",
        "def run_single_generation(rng, elite_size, num_evals_per_gen,\n",
        "                          num_env_steps, network_size, env_params, es_params,\n",
        "                          es_memory, use_jit=True, use_tpu=False):\n",
        "    \"\"\" Run the training loop over a set of epochs. \"\"\"\n",
        "    # Loop over different generations and search!\n",
        "    rng, rng_input = jax.random.split(rng)\n",
        "    x, es_memory = ask(rng_input, es_memory, es_params)\n",
        "    generation_params = flat_to_mlp(x, sizes=network_size)\n",
        "\n",
        "    # Evaluate the fitness of the generation members\n",
        "    rng, rng_input = jax.random.split(rng)\n",
        "    rollout_keys = jax.random.split(rng_input, num_evals_per_gen)\n",
        "\n",
        "    population_returns = generation_rollout(rollout_keys,\n",
        "                                            generation_params,\n",
        "                                            env_params, num_env_steps)\n",
        "\n",
        "    values = - population_returns.mean(axis=1)\n",
        "\n",
        "    # Update the CMA-ES strategy\n",
        "    es_memory = tell(x, values, elite_size, es_params, es_memory)\n",
        "    return\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn8wup4EySun",
        "outputId": "d5ae02ed-2471-4ec6-fa3d-76376458fdfd"
      },
      "source": [
        "import jax.numpy as jnp\n",
        "import time\n",
        "save_fname = \"benchmarks/results/tpu_speed_no_jit\"\n",
        "\n",
        "print(f\"JAX device: {jax.devices()}, {save_fname}\")\n",
        "config = load_config(\"examples/cma_config.json\")\n",
        "train_config, net_config, log_config = (config.train_config,\n",
        "                                        config.net_config,\n",
        "                                        config.log_config)\n",
        "num_evaluations = 1 + 1  # Dont use first - used for compilation\n",
        "population_sizes = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "#network_sizes = [16, 48, 80, 112, 144]\n",
        "network_sizes = [48]\n",
        "store_times = np.zeros((3, len(network_sizes), len(population_sizes)))\n",
        "for i, hidden_size in enumerate(network_sizes):\n",
        "    for j, pop_size in enumerate(population_sizes):\n",
        "        mean, std, jit_t = benchmark_accelerator(num_evaluations, pop_size, hidden_size,\n",
        "                                                  net_config, train_config, log_config,\n",
        "                                                  True, False)\n",
        "        # Jitted time, mean, std\n",
        "        store_times[0, len(network_sizes)-1-i, j] = jit_t\n",
        "        store_times[1, len(network_sizes)-1-i, j] = mean\n",
        "        store_times[2, len(network_sizes)-1-i, j] = std\n",
        "        print(hidden_size, pop_size, mean, std, jit_t)\n",
        "np.save(save_fname, store_times)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JAX device: [TpuDevice(id=0, host_id=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, host_id=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, host_id=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, host_id=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, host_id=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, host_id=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, host_id=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, host_id=0, coords=(1,1,0), core_on_chip=1)], benchmarks/results/tpu_speed_no_jit\n",
            "48 100 1.6559696197509766 0.0 1.6062541007995605\n",
            "48 200 1.730271339416504 0.0 1.6364848613739014\n",
            "48 300 1.9260773658752441 0.0 8.203169107437134\n",
            "48 400 1.8260862827301025 0.0 11.239391803741455\n",
            "48 500 1.945971965789795 0.0 15.34292984008789\n",
            "48 600 2.058655023574829 0.0 19.204785346984863\n",
            "48 700 2.101370096206665 0.0 23.883458852767944\n",
            "48 800 2.2158946990966797 0.0 30.245986223220825\n",
            "48 900 2.4260644912719727 0.0 38.08869552612305\n",
            "48 1000 2.586442232131958 0.0 45.5720739364624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AoljED64ZFF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}