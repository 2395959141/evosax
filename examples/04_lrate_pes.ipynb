{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Persistent ES on Learning Rate Tuning Problem\n",
    "### [Last Update: March 2022][![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/evosax/blob/main/examples/04_mlp_pes.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "!pip install -q git+https://github.com/RobertTLange/evosax.git@main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem as in [Vicol et al. (2021)](http://proceedings.mlr.press/v139/vicol21a/vicol21a-supp.pdf) - Toy 2D Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def loss(x):\n",
    "    \"\"\"Inner loss.\"\"\"\n",
    "    return (\n",
    "        jnp.sqrt(x[0] ** 2 + 5)\n",
    "        - jnp.sqrt(5)\n",
    "        + jnp.sin(x[1]) ** 2 * jnp.exp(-5 * x[0] ** 2)\n",
    "        + 0.25 * jnp.abs(x[1] - 100)\n",
    "    )\n",
    "\n",
    "def update(state, i):\n",
    "    \"\"\"Performs a single inner problem update, e.g., a single unroll step.\"\"\"\n",
    "    (L, x, theta, t_curr, T, K) = state\n",
    "    lr = jnp.exp(theta[0]) * (T - t_curr) / T + jnp.exp(theta[1]) * t_curr / T\n",
    "    x = x - lr * jax.grad(loss)(x)\n",
    "    L += loss(x) * (t_curr < T)\n",
    "    t_curr += 1\n",
    "    return (L, x, theta, t_curr, T, K), x\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3, 4))\n",
    "def unroll(x_init, theta, t0, T, K):\n",
    "    \"\"\"Unroll the inner problem for K steps.\"\"\"\n",
    "    L = 0.0\n",
    "    initial_state = (L, x_init, theta, t0, T, K)\n",
    "    state, outputs = jax.lax.scan(update, initial_state, None, length=K)\n",
    "    (L, x_curr, theta, t_curr, T, K) = state\n",
    "    return L, x_curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Persistent Evolution Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "from evosax import PersistentES\n",
    "\n",
    "popsize = 100\n",
    "\n",
    "strategy = PersistentES(popsize=popsize, num_dims=2)\n",
    "es_params = strategy.default_params.replace(\n",
    "    T=100, K=10\n",
    ")\n",
    "\n",
    "rng = jax.random.PRNGKey(5)\n",
    "state = strategy.initialize(rng, es_params)\n",
    "\n",
    "# Initialize inner parameters\n",
    "t = 0\n",
    "xs = jnp.ones((popsize, 2)) * jnp.array([1.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Outer PES Loop of Inner GD Loops :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.01 -0.01] 2423.4482\n",
      "500 [ 0.08029711 -0.7827603 ] 2423.3083\n",
      "1000 [ 0.17781787 -0.6900547 ] 2423.4324\n",
      "1500 [ 1.7823172 -0.5671913] 1363.6532\n",
      "2000 [ 2.6007807  -0.43554983] 585.6527\n",
      "2500 [ 2.7024412 -0.4344938] 576.2598\n",
      "3000 [ 2.737832   -0.47443515] 576.0917\n",
      "3500 [ 2.7500708 -0.5119995] 565.1986\n",
      "4000 [ 2.750747   -0.51908237] 574.359\n",
      "4500 [ 2.765111  -0.5706135] 573.79443\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    rng, skey = jax.random.split(rng)\n",
    "    if t >= es_params.T:\n",
    "        # Reset the inner problem: iteration, parameters\n",
    "        t = 0\n",
    "        xs = jnp.ones((popsize, 2)) * jnp.array([1.0, 1.0])\n",
    "    x, state = strategy.ask(rng, state, es_params)\n",
    "\n",
    "    # Unroll inner problem for K steps using antithetic perturbations\n",
    "    fitness, xs = jax.vmap(unroll, in_axes=(0, 0, None, None, None))(\n",
    "        xs, x, t, es_params.T, es_params.K\n",
    "    )\n",
    "    \n",
    "    # Update ES - outer step!\n",
    "    state = strategy.tell(x, fitness, state, es_params)\n",
    "    t += es_params.K\n",
    "\n",
    "    # Evaluation!\n",
    "    if i % 500 == 0:\n",
    "        L, _ = unroll(\n",
    "            jnp.array([1.0, 1.0]), state.mean, 0, es_params.T, es_params.T\n",
    "        )\n",
    "        print(i, state.mean, L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-toolbox",
   "language": "python",
   "name": "mle-toolbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
