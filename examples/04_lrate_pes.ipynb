{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Persistent ES on Learning Rate Tuning Problem\n",
    "### [Last Update: February 2022][![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/evosax/blob/main/examples/04_mlp_pes.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax import Persistent_ES\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "\n",
    "popsize = 100\n",
    "T = 100\n",
    "K = 10\n",
    "\n",
    "def loss(x):\n",
    "    \"\"\"Inner loss.\"\"\"\n",
    "    return (\n",
    "        jnp.sqrt(x[0] ** 2 + 5)\n",
    "        - jnp.sqrt(5)\n",
    "        + jnp.sin(x[1]) ** 2 * jnp.exp(-5 * x[0] ** 2)\n",
    "        + 0.25 * jnp.abs(x[1] - 100)\n",
    "    )\n",
    "\n",
    "# Gradient of inner loss\n",
    "loss_grad = jax.grad(loss)\n",
    "\n",
    "def update(state, i):\n",
    "    \"\"\"Performs a single inner problem update, e.g., a single unroll step.\"\"\"\n",
    "    (L, x, theta, t_curr, T, K) = state\n",
    "    lr = jnp.exp(theta[0]) * (T - t_curr) / T + jnp.exp(theta[1]) * t_curr / T\n",
    "    x = x - lr * loss_grad(x)\n",
    "    L += loss(x) * (t_curr < T)\n",
    "    t_curr += 1\n",
    "    return (L, x, theta, t_curr, T, K), x\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3, 4))\n",
    "def unroll(x_init, theta, t0, T, K):\n",
    "    \"\"\"Unroll the inner problem for K steps.\"\"\"\n",
    "    L = 0.0\n",
    "    initial_state = (L, x_init, theta, t0, T, K)\n",
    "    state, outputs = jax.lax.scan(update, initial_state, None, length=K)\n",
    "    (L, x_curr, theta, t_curr, T, K) = state\n",
    "    return L, x_curr\n",
    "\n",
    "strategy = Persistent_ES(popsize=100, num_dims=2)\n",
    "params = strategy.default_params\n",
    "rng = jax.random.PRNGKey(5)\n",
    "state = strategy.initialize(rng, params)\n",
    "\n",
    "# Initialize inner parameters\n",
    "t = 0\n",
    "theta = jnp.log(jnp.array([0.01, 0.01]))\n",
    "x = jnp.array([1.0, 1.0])\n",
    "xs = jnp.ones((popsize, 2)) * jnp.array([1.0, 1.0])\n",
    "\n",
    "for i in range(10000):\n",
    "    rng, skey = jax.random.split(rng)\n",
    "    if t >= params[\"T\"]:\n",
    "        # Reset the inner problem: iteration, parameters\n",
    "        t = 0\n",
    "        xs = jnp.ones((popsize, 2)) * jnp.array([1.0, 1.0])\n",
    "        x = jnp.array([1.0, 1.0])\n",
    "    theta_gen, state = strategy.ask(rng, state, params)\n",
    "\n",
    "    # Unroll inner problem for K steps using antithetic perturbations\n",
    "    L, xs = jax.vmap(unroll, in_axes=(0, 0, None, None, None))(\n",
    "        xs, theta_gen, t, params[\"T\"], params[\"K\"]\n",
    "    )\n",
    "\n",
    "    state = strategy.tell(theta_gen, L, state, params)\n",
    "    t += params[\"K\"]\n",
    "\n",
    "    # Teset evaluation!\n",
    "    if i % 1000 == 0:\n",
    "        L, _ = unroll(\n",
    "            jnp.array([1.0, 1.0]), state[\"mean\"], 0, params[\"T\"], params[\"T\"]\n",
    "        )\n",
    "        print(i, state[\"mean\"], L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ma-vision)",
   "language": "python",
   "name": "ma-vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
